{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "sYaR88cx3yIC"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoOv1J8meRvA",
        "outputId": "38bf2f0f-8b23-462b-8d7f-5371fb303e0c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics --quiet\n",
        "!pip install deep_sort_realtime --quiet\n",
        "!pip install motmetrics --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3UIqiS9fIVZ",
        "outputId": "1ad8ce36-38a5-4708-ab94-be1b4f0f9ae1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m914.9/914.9 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.5/161.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchvision.transforms import functional as F\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
        "from ultralytics import YOLO\n",
        "from IPython.display import Video, display\n",
        "import motmetrics as mm\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "mXy6mfpWf7q_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Folder"
      ],
      "metadata": {
        "id": "sYaR88cx3yIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration\n",
        "INPUT_FRAMES_DIR = \"/content/drive/My Drive/SportsMOT/test/img1\"\n",
        "OUTPUT_VIDEO_PATH = \"/content/drive/My Drive/SportsMOT/output_video_Deepsort_test.mp4\"\n",
        "MODEL_WEIGHTS_PATH = \"/content/drive/My Drive/SportsMOT/best.pt\"\n",
        "RESULTS_DIR = \"/content/drive/My Drive/SportsMOT/\"\n",
        "RESULTS_TEXT = \"tracking_results_deepsort.txt\"\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "CLASS_NAMES = [\"player\", \"referee\", \"ball\"]  # Update with your class names\n",
        "CLASS_COLORS = {\n",
        "    \"player\": (255, 255, 0),    # Green\n",
        "    \"referee\": (0, 0, 255),   # Red\n",
        "    \"ball\": (255, 0, 255)       # Blue\n",
        "}\n",
        "MIN_CONFIDENCE = 0.5          # Minimum detection confidence\n",
        "FRAME_SIZE = (1280, 720)      # Should match your frame size\n",
        "FPS = 25                      # Adjust based on your video"
      ],
      "metadata": {
        "id": "5JHn7BBfgAvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tracker = DeepSort(max_age=5, n_init=1, nms_max_overlap=0.2)"
      ],
      "metadata": {
        "id": "XzM8INA1j25F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load YOLOv8 model\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "yolo_model = YOLO(MODEL_WEIGHTS_PATH).to(device)"
      ],
      "metadata": {
        "id": "AHLDEoVGgGvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get sorted list of frame files\n",
        "frame_files = sorted([f for f in os.listdir(INPUT_FRAMES_DIR) if f.endswith(('.jpg', '.png'))],\n",
        "                     key=lambda x: int(x.split('.')[0]))\n",
        "\n",
        "# Initialize video writer\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "video_writer = cv2.VideoWriter(OUTPUT_VIDEO_PATH, fourcc, FPS, FRAME_SIZE)"
      ],
      "metadata": {
        "id": "h_sLqMg1gI5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CLASS_COLORS = {\n",
        "    \"ball\": (0,200,200),\n",
        "    \"player\": (255,255,0),\n",
        "    \"referee\": (0,0,255),\n",
        "}"
      ],
      "metadata": {
        "id": "paTHHcbWv0GT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for MP4 output\n",
        "video_writer = cv2.VideoWriter(OUTPUT_VIDEO_PATH, fourcc, FPS, FRAME_SIZE)\n",
        "\n",
        "# Process frames and track objects\n",
        "for frame_idx, frame_file in enumerate(frame_files):\n",
        "\n",
        "    frame_path = os.path.join(INPUT_FRAMES_DIR, frame_file)\n",
        "    frame = cv2.imread(frame_path)\n",
        "    frame = cv2.resize(frame, FRAME_SIZE)  # Ensure 720p resolution\n",
        "\n",
        "    # Run YOLO model for detection\n",
        "    results = yolo_model(frame, device=device, verbose=False)[0]  # Ensure it's the first result\n",
        "\n",
        "    processed_boxes = []\n",
        "    if results.boxes is not None:\n",
        "        boxes = results.boxes.xyxy.cpu().numpy()  # Ensure correct format\n",
        "        confidences = results.boxes.conf.cpu().numpy()\n",
        "\n",
        "        # Filter low-confidence detections\n",
        "        for i, box in enumerate(boxes):\n",
        "            if confidences[i] < 0.4:  # Confidence threshold\n",
        "                continue\n",
        "            xmin, ymin, xmax, ymax = map(int, box)\n",
        "            width, height = xmax - xmin, ymax - ymin\n",
        "            processed_boxes.append([[xmin, ymin, width, height], confidences[i]])\n",
        "\n",
        "    # Update DeepSORT tracker\n",
        "    tracks = tracker.update_tracks(processed_boxes, frame=frame)\n",
        "    with open(os.path.join(RESULTS_DIR, RESULTS_TEXT), \"a\") as f:\n",
        "        for track in tracks:\n",
        "            if not track.is_confirmed():\n",
        "                continue\n",
        "            track_id = track.track_id\n",
        "            class_name = track.det_class\n",
        "            color = CLASS_COLORS.get(class_name, (255, 255, 255))\n",
        "\n",
        "            frame_num = frame_idx + 1  # You need to track this\n",
        "            track_id = track.track_id\n",
        "            x1, y1, x2, y2 = track.to_ltrb()\n",
        "            conf = str(track.det_conf)[:4]\n",
        "\n",
        "            line = f\"{frame_num},{track_id},{x1},{y1},{x2-x1},{y2-y1},{conf},-1,-1,-1\\n\"\n",
        "            f.write(line)\n",
        "\n",
        "            x1, y1, w, h = map(int, track.to_ltwh())  # Convert to correct format\n",
        "            x2, y2 = x1 + w, y1 + h\n",
        "            label = f\"{track_id}. {class_name} ({conf})\"\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 255, 0), 2)\n",
        "            cv2.putText(frame, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)\n",
        "\n",
        "    # Write frame to video\n",
        "    video_writer.write(frame)\n",
        "\n",
        "video_writer.release()\n",
        "print(\"Processing completed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbSJRIKdtF1a",
        "outputId": "56edb7e1-6c5f-43cb-a14c-83be31939ece"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_mot_metrics(gt_file, ts_file, seqmap_file=None):\n",
        "\n",
        "    # Load ground truth and tracking results\n",
        "    gt = mm.io.load_motchallenge(gt_file)\n",
        "    ts = mm.io.load_motchallenge(ts_file)\n",
        "\n",
        "    # Calculate metrics\n",
        "    acc = mm.utils.compare_to_groundtruth(gt, ts, 'iou', distth=0.5)\n",
        "    mh = mm.metrics.create()\n",
        "    summary = mh.compute(acc, metrics=[\n",
        "        'mota', 'precision', 'recall', 'motp', 'idf1', 'idp', 'idr',\n",
        "        'num_switches', 'mostly_tracked',\n",
        "        'partially_tracked', 'mostly_lost'\n",
        "    ], name='acc')\n",
        "\n",
        "    summary_df = pd.DataFrame(summary).transpose()\n",
        "\n",
        "    return summary_df\n",
        "\n",
        "# Usage example\n",
        "gt_path = \"/content/drive/My Drive/SportsMOT/test/gt/corrected_gt.txt\"\n",
        "results_path = \"/content/drive/My Drive/SportsMOT/tracking_results_deepsort.txt\"\n",
        "metrics_summary = compute_mot_metrics(gt_path, results_path)\n",
        "print(metrics_summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K48o4SjE3Xgw",
        "outputId": "6d0e158d-d7c4-4ba9-a6a7-799b43e3102c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                         acc\n",
            "mota                0.589685\n",
            "precision           0.903100\n",
            "recall              0.669843\n",
            "motp                0.178865\n",
            "idf1                0.545130\n",
            "idp                 0.640045\n",
            "idr                 0.474731\n",
            "num_switches       40.000000\n",
            "mostly_tracked      7.000000\n",
            "partially_tracked  11.000000\n",
            "mostly_lost         3.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Video"
      ],
      "metadata": {
        "id": "J5iBbUIF31Hi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# These should be replaced with the actual imports from your YOLO and DeepSORT modules.\n",
        "# For example:\n",
        "# from your_yolo_module import YOLO\n",
        "# from your_deepsort_module import DeepSort\n",
        "\n",
        "class VideoTracker:\n",
        "    def __init__(self,\n",
        "                 input_video_path: str,\n",
        "                 output_video_path: str,\n",
        "                 model_weights_path: str,\n",
        "                 results_dir: str,\n",
        "                 results_text: str = \"tracking_results_deepsort.txt\",\n",
        "                 class_names: list = None,\n",
        "                 class_colors: dict = None,\n",
        "                 min_confidence: float = 0.5,\n",
        "                 frame_size: tuple = (1280, 720),\n",
        "                 fps: int = 25,\n",
        "                 device: str = None):\n",
        "        \"\"\"\n",
        "        Initializes the VideoTracker with configuration settings.\n",
        "        \"\"\"\n",
        "        self.input_video_path = input_video_path\n",
        "        self.output_video_path = output_video_path\n",
        "        self.model_weights_path = model_weights_path\n",
        "        self.results_dir = results_dir\n",
        "        self.results_text = results_text\n",
        "        self.min_confidence = min_confidence\n",
        "        self.frame_size = frame_size\n",
        "        self.fps = fps\n",
        "\n",
        "        # Set up class names and colors\n",
        "        self.class_names = class_names if class_names is not None else [\"player\", \"referee\", \"ball\"]\n",
        "        self.class_colors = class_colors if class_colors is not None else {\n",
        "            \"player\": (255, 255, 0),\n",
        "            \"referee\": (0, 0, 255),\n",
        "            \"ball\": (0, 200, 200)\n",
        "        }\n",
        "\n",
        "        # Ensure results directory exists\n",
        "        os.makedirs(self.results_dir, exist_ok=True)\n",
        "\n",
        "        # Device configuration\n",
        "        self.device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        # Load YOLO model and move it to the appropriate device\n",
        "        self.yolo_model = YOLO(self.model_weights_path).to(self.device)\n",
        "\n",
        "        # Initialize DeepSORT tracker\n",
        "        self.tracker = DeepSort(max_age=5, n_init=1, nms_max_overlap=0.2)\n",
        "\n",
        "        # Prepare results text file (overwrite if exists)\n",
        "        self.results_file_path = os.path.join(self.results_dir, self.results_text)\n",
        "        with open(self.results_file_path, \"w\") as f:\n",
        "            f.write(\"\")  # Clear previous content\n",
        "\n",
        "    def process_video(self):\n",
        "        \"\"\"\n",
        "        Processes the input video frame-by-frame, performs detection and tracking,\n",
        "        writes tracking results to a text file, and outputs a new video with annotated tracking.\n",
        "        \"\"\"\n",
        "        # Open the video file\n",
        "        cap = cv2.VideoCapture(self.input_video_path)\n",
        "        if not cap.isOpened():\n",
        "            print(f\"Error: Could not open video {self.input_video_path}\")\n",
        "            return\n",
        "\n",
        "        # Optionally, update FPS and frame size from the video properties if needed\n",
        "        # self.fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "        # width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        # height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        # self.frame_size = (width, height)\n",
        "\n",
        "        # Initialize video writer\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        video_writer = cv2.VideoWriter(self.output_video_path, fourcc, self.fps, self.frame_size)\n",
        "\n",
        "        frame_idx = 0\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break  # End of video\n",
        "\n",
        "            # Resize frame if necessary\n",
        "            frame = cv2.resize(frame, self.frame_size)\n",
        "\n",
        "            # Run YOLO model for detection\n",
        "            results = self.yolo_model(frame, device=self.device, verbose=False)[0]\n",
        "\n",
        "            # Build a detections list where each entry is:\n",
        "            # [ [xmin, ymin, width, height], confidence ]\n",
        "            detections = []\n",
        "            if results.boxes is not None:\n",
        "                boxes = results.boxes.xyxy.cpu().numpy()  # Format: [xmin, ymin, xmax, ymax]\n",
        "                confidences = results.boxes.conf.cpu().numpy()\n",
        "\n",
        "                # Filter low-confidence detections and prepare boxes for DeepSORT\n",
        "                for i, box in enumerate(boxes):\n",
        "                    if confidences[i] < self.min_confidence:\n",
        "                        continue\n",
        "                    xmin, ymin, xmax, ymax = map(int, box)\n",
        "                    width, height = xmax - xmin, ymax - ymin\n",
        "                    # Append in the expected nested format\n",
        "                    detections.append([[xmin, ymin, width, height], confidences[i]])\n",
        "\n",
        "\n",
        "            tracks = self.tracker.update_tracks(detections, frame=frame)\n",
        "\n",
        "            # Open results file in append mode and write tracking results\n",
        "            with open(self.results_file_path, \"a\") as f:\n",
        "                for track in tracks:\n",
        "                    if not track.is_confirmed():\n",
        "                        continue\n",
        "\n",
        "                    track_id = track.track_id\n",
        "                    class_name = track.det_class if hasattr(track, 'det_class') else \"unknown\"\n",
        "                    color = self.class_colors.get(class_name, (255, 255, 255))\n",
        "                    frame_num = frame_idx + 1\n",
        "                    x1, y1, x2, y2 = track.to_ltrb()  # Left, Top, Right, Bottom\n",
        "\n",
        "                    # Use the confidence score passed from the detection.\n",
        "                    # Depending on your DeepSORT implementation, the confidence might be stored as 'det_conf' or 'score'.\n",
        "                    conf_value = (track.det_conf if hasattr(track, 'det_conf') and track.det_conf is not None\n",
        "                                  else (track.score if hasattr(track, 'score') else 0.0))\n",
        "                    conf_str = f\"{conf_value:.2f}\"\n",
        "\n",
        "                    # Write a line to the results file (customize the format as needed)\n",
        "                    line = f\"{frame_num},{track_id},{x1},{y1},{x2 - x1},{y2 - y1},{conf_str},-1,-1,-1\\n\"\n",
        "                    f.write(line)\n",
        "\n",
        "                    # Draw bounding box and label on the frame\n",
        "                    x1_ltwh, y1_ltwh, w, h = map(int, track.to_ltwh())  # Left, Top, Width, Height\n",
        "                    x2_ltwh, y2_ltwh = x1_ltwh + w, y1_ltwh + h\n",
        "                    label = f\"{track_id}. {class_name} ({conf_str})\"\n",
        "                    cv2.rectangle(frame, (x1_ltwh, y1_ltwh), (x2_ltwh, y2_ltwh), color, 2)\n",
        "                    cv2.putText(frame, label, (x1_ltwh, y1_ltwh - 5),\n",
        "                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "            # Write annotated frame to output video\n",
        "            video_writer.write(frame)\n",
        "            frame_idx += 1\n",
        "\n",
        "            # Optionally, display the frame (useful for debugging)\n",
        "            # cv2.imshow(\"Tracking\", frame)\n",
        "            # if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            #     break\n",
        "\n",
        "        # Release resources\n",
        "        cap.release()\n",
        "        video_writer.release()\n",
        "        cv2.destroyAllWindows()\n",
        "        print(\"Processing completed!\")\n"
      ],
      "metadata": {
        "id": "xZu1H-3IKVGD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example configuration paths; update them to your local paths as needed.\n",
        "INPUT_VIDEO_PATH = \"/content/drive/My Drive/SportsMOT/val_video.mp4\"\n",
        "OUTPUT_VIDEO_PATH = \"/content/drive/My Drive/SportsMOT/Deepsort_test3.mp4\"\n",
        "MODEL_WEIGHTS_PATH = \"/content/drive/My Drive/SportsMOT/best.pt\"\n",
        "RESULTS_DIR = \"/content/drive/My Drive/SportsMOT/\"\n",
        "\n",
        "# Initialize and run the video tracker\n",
        "video_tracker = VideoTracker(\n",
        "    input_video_path=INPUT_VIDEO_PATH,\n",
        "    output_video_path=OUTPUT_VIDEO_PATH,\n",
        "    model_weights_path=MODEL_WEIGHTS_PATH,\n",
        "    results_dir=RESULTS_DIR,\n",
        "    results_text=\"tracking_results_deepsort_test3.txt\",\n",
        "    class_names=[\"player\", \"referee\", \"ball\"],\n",
        "    class_colors={\n",
        "        \"player\": (255, 255, 0),\n",
        "        \"referee\": (0, 0, 255),\n",
        "        \"ball\": (0, 200, 200)\n",
        "    },\n",
        "    min_confidence=0.6,\n",
        "    frame_size=(1280, 720),\n",
        "    fps=25\n",
        ")\n",
        "video_tracker.process_video()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOibpjtj3Jfq",
        "outputId": "becccecb-45d8-40af-90f7-0818e400dc16"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4197095\n",
            "0.43135095\n",
            "0.2929616\n",
            "0.30777073\n",
            "0.29193318\n",
            "0.5819921\n",
            "0.42822853\n",
            "0.32581773\n",
            "0.5380466\n",
            "0.38887408\n",
            "0.58681077\n",
            "0.58630705\n",
            "0.5477887\n",
            "0.33716324\n",
            "0.5312546\n",
            "0.5484758\n",
            "0.4276119\n",
            "0.3256879\n",
            "0.5901515\n",
            "0.44657636\n",
            "0.5644242\n",
            "0.27396992\n",
            "0.58073676\n",
            "0.27116233\n",
            "0.4749948\n",
            "0.5902271\n",
            "0.53943187\n",
            "0.28322405\n",
            "0.29237664\n",
            "0.4896696\n",
            "0.46537006\n",
            "0.5964763\n",
            "0.40997365\n",
            "0.58495045\n",
            "0.45915464\n",
            "0.3102826\n",
            "0.5345808\n",
            "0.31596968\n",
            "0.34848672\n",
            "0.46936348\n",
            "0.2573932\n",
            "0.2589684\n",
            "0.3986963\n",
            "0.39947644\n",
            "0.5799786\n",
            "0.5752865\n",
            "0.27773556\n",
            "0.28615484\n",
            "0.3753249\n",
            "0.45267406\n",
            "0.35024384\n",
            "0.29064927\n",
            "0.5612895\n",
            "0.4537589\n",
            "0.48332566\n",
            "0.5997306\n",
            "0.30687627\n",
            "0.41506106\n",
            "0.3511913\n",
            "0.36381295\n",
            "0.46545485\n",
            "0.36579612\n",
            "0.25455981\n",
            "0.46428975\n",
            "0.35503697\n",
            "0.2543344\n",
            "0.2665312\n",
            "0.27504358\n",
            "0.29762483\n",
            "0.5695777\n",
            "0.38936582\n",
            "0.35039425\n",
            "0.36988258\n",
            "0.3468441\n",
            "0.30030322\n",
            "0.29216012\n",
            "0.342135\n",
            "0.26230633\n",
            "0.38856885\n",
            "0.39515698\n",
            "0.34158197\n",
            "0.48937005\n",
            "0.3398411\n",
            "0.55049324\n",
            "0.34926674\n",
            "0.5812318\n",
            "0.3683327\n",
            "0.2754229\n",
            "0.2898261\n",
            "0.2716924\n",
            "0.5530433\n",
            "0.5154727\n",
            "0.4156447\n",
            "0.46981695\n",
            "0.44670144\n",
            "0.36058986\n",
            "0.47015157\n",
            "0.3325015\n",
            "0.5927419\n",
            "0.36815542\n",
            "0.34167773\n",
            "0.27315536\n",
            "0.47910297\n",
            "0.36527216\n",
            "0.261808\n",
            "0.51583546\n",
            "0.28596747\n",
            "0.5350481\n",
            "0.52858925\n",
            "0.36875537\n",
            "0.27004132\n",
            "0.5473755\n",
            "0.34507167\n",
            "0.36816654\n",
            "0.31112692\n",
            "0.5203856\n",
            "0.26329657\n",
            "0.45870766\n",
            "0.53868145\n",
            "0.5812833\n",
            "0.47968003\n",
            "0.42117354\n",
            "0.59994537\n",
            "0.59903395\n",
            "0.46031544\n",
            "0.5970938\n",
            "0.25797322\n",
            "0.29773796\n",
            "0.3604069\n",
            "0.5395403\n",
            "0.4988992\n",
            "0.33382657\n",
            "0.2855365\n",
            "0.27349982\n",
            "0.42851773\n",
            "0.40767986\n",
            "0.5969939\n",
            "0.2594588\n",
            "0.29333824\n",
            "0.4361881\n",
            "0.2628241\n",
            "0.44444123\n",
            "0.35391262\n",
            "0.38190997\n",
            "0.5581593\n",
            "0.40743446\n",
            "0.43689325\n",
            "0.44277427\n",
            "0.5486721\n",
            "0.38351074\n",
            "0.32584372\n",
            "0.3616626\n",
            "0.43898654\n",
            "0.55826867\n",
            "0.43491688\n",
            "0.2804902\n",
            "0.5296685\n",
            "0.4388494\n",
            "0.5250585\n",
            "0.29409754\n",
            "0.32784122\n",
            "0.55669236\n",
            "0.29343987\n",
            "0.56622374\n",
            "0.59619325\n",
            "0.5211367\n",
            "0.5485858\n",
            "0.43646556\n",
            "0.46433422\n",
            "0.46995923\n",
            "0.3279372\n",
            "0.37686095\n",
            "0.35336655\n",
            "0.34402603\n",
            "0.27387652\n",
            "0.5928276\n",
            "0.41886124\n",
            "0.35222223\n",
            "0.34292966\n",
            "0.5630289\n",
            "0.31087434\n",
            "0.26145872\n",
            "0.4181256\n",
            "0.27844816\n",
            "0.25896162\n",
            "0.3309245\n",
            "0.30107117\n",
            "0.3028574\n",
            "0.29953122\n",
            "0.5598722\n",
            "0.39247397\n",
            "0.51470464\n",
            "0.4837375\n",
            "0.28886396\n",
            "0.5345207\n",
            "0.4238672\n",
            "0.54854953\n",
            "0.43368655\n",
            "0.46692988\n",
            "0.43717515\n",
            "0.2961778\n",
            "0.2647237\n",
            "0.5289481\n",
            "0.5576832\n",
            "0.36633268\n",
            "0.57554466\n",
            "0.2998129\n",
            "0.4092916\n",
            "0.33675823\n",
            "0.29987708\n",
            "0.32927525\n",
            "0.27382672\n",
            "0.28402317\n",
            "0.2833938\n",
            "0.3471324\n",
            "0.5947915\n",
            "0.28629026\n",
            "0.41920742\n",
            "0.26602474\n",
            "0.5704503\n",
            "0.3631644\n",
            "0.5203021\n",
            "0.2773013\n",
            "0.44010237\n",
            "0.27291006\n",
            "0.4447501\n",
            "0.28711355\n",
            "0.5805942\n",
            "0.5072627\n",
            "0.4612841\n",
            "0.3558983\n",
            "0.39083293\n",
            "0.5172519\n",
            "0.2792591\n",
            "0.36763948\n",
            "0.33325163\n",
            "0.45619875\n",
            "0.40753648\n",
            "0.5286384\n",
            "0.40501237\n",
            "0.35687423\n",
            "0.3037776\n",
            "0.49542633\n",
            "0.32593632\n",
            "0.32563153\n",
            "0.27820528\n",
            "0.43321443\n",
            "0.3270039\n",
            "0.4732075\n",
            "0.28403014\n",
            "0.30133593\n",
            "0.5193697\n",
            "0.3042723\n",
            "0.29991513\n",
            "0.31295267\n",
            "0.26462162\n",
            "0.34363377\n",
            "0.5031247\n",
            "0.59026206\n",
            "0.36552203\n",
            "0.3697528\n",
            "0.33046433\n",
            "0.53135616\n",
            "0.51903117\n",
            "0.3894674\n",
            "0.57776386\n",
            "0.41039786\n",
            "0.4336348\n",
            "0.4337534\n",
            "0.43699038\n",
            "0.42189103\n",
            "0.5332809\n",
            "0.53185195\n",
            "0.4562716\n",
            "0.43601546\n",
            "0.3992884\n",
            "0.35806826\n",
            "0.25544015\n",
            "0.38947684\n",
            "0.33366138\n",
            "0.48435163\n",
            "0.5500631\n",
            "0.35425732\n",
            "0.37813407\n",
            "Processing completed!\n"
          ]
        }
      ]
    }
  ]
}